# üîí Protection Anti-Indexation - Guide Complet

## Pourquoi c'est critique ?

Votre dashboard LinkedIn Bot est **priv√©** et contient des informations sensibles :
- Acc√®s √† votre compte LinkedIn via cookies
- Historique de vos messages
- Configuration de votre bot
- Statistiques d'utilisation

**Si Google indexe votre dashboard** :
- ‚ùå Votre URL appara√Æt dans les r√©sultats de recherche
- ‚ùå Attaquants peuvent trouver votre dashboard facilement
- ‚ùå Risque d'exposition de donn√©es sensibles (screenshots Google)
- ‚ùå Surface d'attaque augment√©e (brute-force cibl√©)

---

## üõ°Ô∏è Protections Impl√©ment√©es (Multi-couches)

Nous avons mis en place **4 couches de protection** ind√©pendantes :

### Couche 1 : robots.txt ‚úÖ
**Fichier** : `dashboard/public/robots.txt`

**Fonction** : Demande poliment aux robots de ne pas indexer

**Efficacit√©** : ‚≠ê‚≠ê‚≠ê Moyenne (les robots malveillants l'ignorent)

**Exemple** :
```
User-agent: *
Disallow: /

User-agent: Googlebot
Disallow: /
```

**V√©rification** :
```bash
curl https://VOTRE_DOMAINE.COM/robots.txt
```

### Couche 2 : Meta Tags Noindex ‚úÖ
**Fichier** : `dashboard/app/layout.tsx`

**Fonction** : Balises HTML demandant aux moteurs de ne pas indexer

**Efficacit√©** : ‚≠ê‚≠ê‚≠ê‚≠ê Bonne (Google et Bing respectent)

**Code** :
```tsx
export const metadata: Metadata = {
  robots: {
    index: false,
    follow: false,
    nocache: true,
    googleBot: {
      index: false,
      noimageindex: true,
    },
  },
};
```

**G√©n√®re** :
```html
<meta name="robots" content="noindex, nofollow, nocache">
<meta name="googlebot" content="noindex, nofollow, noimageindex">
```

**V√©rification** :
```bash
curl -s https://VOTRE_DOMAINE.COM | grep -i "robots"
```

### Couche 3 : Header HTTP X-Robots-Tag (Next.js) ‚úÖ
**Fichier** : `dashboard/next.config.js`

**Fonction** : Header HTTP envoy√© √† chaque requ√™te

**Efficacit√©** : ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellente (prioritaire sur meta tags)

**Header** :
```
X-Robots-Tag: noindex, nofollow, noarchive, nosnippet, noimageindex, nocache
```

**Signification** :
- `noindex` : Ne pas ajouter √† l'index Google
- `nofollow` : Ne pas suivre les liens
- `noarchive` : Pas de cache Google (pas de "Version en cache")
- `nosnippet` : Pas d'extrait dans r√©sultats
- `noimageindex` : Pas d'indexation des images
- `nocache` : Pas de mise en cache

**V√©rification** :
```bash
curl -I https://VOTRE_DOMAINE.COM | grep -i "x-robots"
```

### Couche 4 : Header HTTP X-Robots-Tag (Nginx) ‚úÖ
**Fichier** : `deployment/nginx/linkedin-bot.conf`

**Fonction** : Header ajout√© par Nginx (double s√©curit√©)

**Efficacit√©** : ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellente (m√™me si Next.js √©choue)

**Configuration** :
```nginx
add_header X-Robots-Tag "noindex, nofollow, noarchive, nosnippet, noimageindex, nocache" always;
```

**V√©rification** :
```bash
curl -I https://VOTRE_DOMAINE.COM | grep -i "x-robots"
# Doit afficher : x-robots-tag: noindex, nofollow, ...
```

---

## üß™ Tests de V√©rification

### Test 1 : V√©rifier robots.txt

```bash
# Doit retourner "Disallow: /"
curl https://VOTRE_DOMAINE.COM/robots.txt
```

**R√©sultat attendu** :
```
User-agent: *
Disallow: /
```

### Test 2 : V√©rifier Meta Tags

```bash
# Doit contenir <meta name="robots" content="noindex...">
curl -s https://VOTRE_DOMAINE.COM | grep -o '<meta name="robots"[^>]*>'
```

**R√©sultat attendu** :
```html
<meta name="robots" content="noindex, nofollow, nocache">
```

### Test 3 : V√©rifier Header HTTP

```bash
# Doit afficher "x-robots-tag: noindex..."
curl -I https://VOTRE_DOMAINE.COM | grep -i "x-robots"
```

**R√©sultat attendu** :
```
x-robots-tag: noindex, nofollow, noarchive, nosnippet, noimageindex, nocache
```

### Test 4 : Google Search Console

Attendez 1-2 semaines puis v√©rifiez que votre site n'appara√Æt pas dans Google :

```
site:VOTRE_DOMAINE.COM
```

**R√©sultat attendu** : Aucun r√©sultat trouv√©

---

## üö® Que faire si votre site est d√©j√† index√© ?

### √âtape 1 : V√©rifier l'indexation actuelle

```bash
# Rechercher votre domaine dans Google
https://www.google.com/search?q=site:VOTRE_DOMAINE.COM
```

### √âtape 2 : Demander la suppression imm√©diate

**Google Search Console** :
1. Allez sur https://search.google.com/search-console
2. Ajoutez votre propri√©t√© (domaine)
3. Allez dans **Suppressions** ‚Üí **Nouvelle demande**
4. Entrez l'URL de votre dashboard
5. S√©lectionnez "Supprimer temporairement l'URL"
6. Validez

**D√©lai** : 24-48 heures (temporaire)

### √âtape 3 : Suppression d√©finitive

Avec les protections en place (robots.txt + X-Robots-Tag), Google va :
1. D√©tecter le `noindex` lors du prochain crawl
2. Retirer votre site de l'index d√©finitivement
3. **D√©lai** : 1-4 semaines

### √âtape 4 : Bing / Autres moteurs

**Bing Webmaster Tools** :
1. https://www.bing.com/webmasters
2. M√™me processus que Google

**Autres moteurs** :
- Yandex : https://webmaster.yandex.com/
- DuckDuckGo : Respecte automatiquement robots.txt

---

## üìä Monitoring Continu

### Alertes Google

Configurez une alerte Google pour √™tre notifi√© si votre site appara√Æt :

1. Allez sur https://www.google.com/alerts
2. Cr√©ez une alerte avec : `site:VOTRE_DOMAINE.COM`
3. Fr√©quence : **Au fil de l'eau**
4. Email de notification : Votre email

### Script de V√©rification Automatique

Ajoutez √† votre cron quotidien :

```bash
#!/bin/bash
# /home/pi/check-indexation.sh

DOMAIN="VOTRE_DOMAINE.COM"
RESULTS=$(curl -s "https://www.google.com/search?q=site:${DOMAIN}" | grep -o "About [0-9,]* results")

if [ -n "$RESULTS" ]; then
  echo "‚ö†Ô∏è WARNING: Site appears to be indexed in Google!"
  echo "$RESULTS"
  # Envoyer email d'alerte
  echo "Site indexed: $RESULTS" | mail -s "ALERT: Dashboard Indexed" votre@email.com
else
  echo "‚úÖ OK: Site not indexed"
fi
```

```bash
# Ajouter au cron
crontab -e
# Ajouter :
0 2 * * * /home/pi/check-indexation.sh
```

---

## üîê Protections Compl√©mentaires

### 1. Authentification Obligatoire

Votre dashboard a d√©j√† une authentification JWT, mais vous pouvez ajouter :

**Basic Auth Nginx** (double protection) :

```nginx
# Dans linkedin-bot.conf, section server
location / {
    auth_basic "Restricted Access";
    auth_basic_user_file /etc/nginx/.htpasswd;

    # ... reste de la config proxy ...
}
```

Cr√©er le fichier `.htpasswd` :

```bash
sudo apt install apache2-utils
sudo htpasswd -c /etc/nginx/.htpasswd admin
# Entrer mot de passe
sudo systemctl reload nginx
```

### 2. IP Whitelisting

Limiter l'acc√®s √† votre IP uniquement :

```nginx
# Dans linkedin-bot.conf
location / {
    # Votre IP publique (√† adapter)
    allow 1.2.3.4;
    deny all;

    # ... reste de la config ...
}
```

Trouver votre IP publique :

```bash
curl https://ifconfig.me
```

### 3. Blocage G√©ographique

Si vous √™tes toujours en France, bloquer les autres pays :

```nginx
# Installer ngx_http_geoip_module
sudo apt install nginx-module-geoip

# Dans nginx.conf
http {
    geoip_country /usr/share/GeoIP/GeoIP.dat;

    map $geoip_country_code $allowed_country {
        default no;
        FR yes;  # France uniquement
    }
}

# Dans linkedin-bot.conf
if ($allowed_country = no) {
    return 403;
}
```

---

## üìù Checklist Anti-Indexation

Avant de valider que tout est OK :

- [ ] `robots.txt` cr√©√© et accessible (`curl /robots.txt`)
- [ ] Meta tags noindex dans le code source (`curl -s / | grep robots`)
- [ ] Header X-Robots-Tag pr√©sent (`curl -I / | grep -i x-robots`)
- [ ] Nginx recharg√© (`sudo systemctl reload nginx`)
- [ ] Dashboard red√©ploy√© (`docker compose restart dashboard`)
- [ ] Test Google Search (`site:VOTRE_DOMAINE.COM` = 0 r√©sultats)
- [ ] Alerte Google configur√©e
- [ ] Script de monitoring en cron (optionnel)

---

## üÜò D√©pannage

### Probl√®me : Header X-Robots-Tag absent

**V√©rifier Next.js** :

```bash
# Red√©ployer dashboard
docker compose -f docker-compose.pi4-standalone.yml restart dashboard

# V√©rifier logs
docker compose logs dashboard | grep -i "robots"
```

**V√©rifier Nginx** :

```bash
# Tester config
sudo nginx -t

# Recharger
sudo systemctl reload nginx

# V√©rifier logs
sudo tail -f /var/log/nginx/linkedin-bot-error.log
```

### Probl√®me : Site toujours index√© apr√®s 2 semaines

1. V√©rifier que les headers sont bien envoy√©s (`curl -I`)
2. Forcer recrawl Google Search Console ‚Üí Inspection URL ‚Üí Demander indexation
3. Google va d√©tecter le `noindex` et supprimer
4. Patience : Peut prendre jusqu'√† 1 mois

### Probl√®me : Robots.txt non accessible

```bash
# V√©rifier que le fichier existe
ls -la /home/pi/linkedin-birthday-auto/dashboard/public/robots.txt

# Next.js sert automatiquement /public/robots.txt sur /robots.txt
# Si pas accessible, v√©rifier build Next.js
docker compose logs dashboard
```

---

## üìö Ressources

- [Google : G√©rer l'indexation](https://developers.google.com/search/docs/crawling-indexing/block-indexing)
- [Robots.txt Specification](https://www.robotstxt.org/)
- [X-Robots-Tag Documentation](https://developers.google.com/search/docs/crawling-indexing/robots-meta-tag)

---

**Auteur** : Audit S√©curit√© 2025
**Version** : 1.0
**Date** : 10 D√©cembre 2025
