# Docker Compose pour Raspberry Pi 4 - Configuration Standalone
# Tout-en-un : Bot Worker + Dashboard + Redis + Nginx (Proxy)
# Autonome : Aucune d√©pendance externe (NAS/MySQL)
#
# Architecture simplifi√©e:
# - Pi4 : Bot Worker + Dashboard + Redis + SQLite + Nginx
# - Freebox Pop : IP r√©sidentielle l√©gitime pour LinkedIn
#
# Utilisation:
#   docker compose -f docker-compose.yml up -d
#
# Documentation:
# - Setup: docs/RASPBERRY_PI_DOCKER_SETUP.md
# - Troubleshooting: docs/RASPBERRY_PI_TROUBLESHOOTING.md
# - Verification: ./scripts/verify_rpi_docker.sh
#
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# AUDIT V3.3 - CORRECTIONS S√âCURIT√â & STABILIT√â (2025-01)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#
# [SEC-1] SUPPRESSION 'privileged: true' sur l'API
#         ‚Üí L'API n'a plus besoin d'acc√®s root au syst√®me h√¥te
#         ‚Üí Gestion des conteneurs via socket Docker (/var/run/docker.sock)
#
# [FIX-A] sysctls vm.overcommit_memory SUPPRIM√â des conteneurs
#         ‚Üí Ce param√®tre kernel n'est PAS namespaceable sur ARM64
#         ‚Üí Doit √™tre configur√© sur l'H√îTE via: sudo sysctl vm.overcommit_memory=1
#         ‚Üí Script fourni: scripts/configure_rpi4_kernel.sh
#
# [FIX-D] DNS fiables forc√©s sur le r√©seau Docker
#         ‚Üí √âvite les timeouts DNS sur box FAI (Freebox, etc.)
#         ‚Üí Utilise Cloudflare (1.1.1.1) et Google (8.8.8.8) comme fallback
#
# IMPORTANT - Limites de ressources:
# Optimis√© pour Raspberry Pi 4 (4GB RAM)
# Les limites m√©moire sont strictes pour √©viter les OOM Kills
# Total allou√©: ~3.7GB (marge de 300MB pour l'OS)

services:
  # ========================================
  # REDIS (Queue pour Bot Worker)
  # ========================================
  redis-bot:
    image: redis:7-alpine
    container_name: redis-bot
    volumes:
    - redis-bot-data:/data
    # Optimisations Redis pour Pi 4
    # AOF only (no RDB snapshots) to avoid fork-based BGSAVE warnings
    command: >
      redis-server
      --appendonly yes
      --appendfsync everysec
      --no-appendfsync-on-rewrite yes
      --maxmemory 128mb
      --maxmemory-policy allkeys-lru
      --loglevel warning
      --tcp-backlog 511
    # [FIX-A] sysctls SUPPRIM√âS - vm.overcommit_memory n'est pas namespaceable sur ARM64
    # Le param√®tre doit √™tre configur√© sur l'H√îTE via scripts/configure_rpi4_kernel.sh
    # net.core.somaxconn remplac√© par --tcp-backlog dans la commande Redis
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 128M
        reservations:
          cpus: '0.25'
          memory: 64M
    logging:
      driver: json-file
      options:
        max-size: 5m
        max-file: '2'
        compress: 'true'
    restart: unless-stopped
    healthcheck:
      test: [CMD, redis-cli, ping]
      interval: 30s
      timeout: 5s
      retries: 3
    networks:
    - linkedin-network

  # ========================================
  # REDIS (Cache pour Dashboard)
  # ========================================
  redis-dashboard:
    image: redis:7-alpine
    container_name: redis-dashboard
    # Cache only (no persistence) to avoid fork operations and memory overcommit warnings
    command: >
      redis-server
      --maxmemory 64mb
      --maxmemory-policy allkeys-lru
      --save ""
      --appendonly no
      --loglevel warning
      --tcp-backlog 511
    # [FIX-A] sysctls SUPPRIM√âS - vm.overcommit_memory n'est pas namespaceable sur ARM64
    # Le param√®tre doit √™tre configur√© sur l'H√îTE via scripts/configure_rpi4_kernel.sh
    restart: unless-stopped
    volumes:
    - redis-dashboard-data:/data
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 128M
        reservations:
          cpus: '0.25'
          memory: 64M
    logging:
      driver: json-file
      options:
        max-size: 5m
        max-file: '2'
        compress: 'true'
    healthcheck:
      test: [CMD, redis-cli, ping]
      interval: 30s
      timeout: 5s
      retries: 3
    networks:
    - linkedin-network

  # ========================================
  # DOCKER SOCKET PROXY (S√©curit√©: Limiter acc√®s Docker)
  # ========================================
  docker-socket-proxy:
    image: tecnativa/docker-socket-proxy:latest
    container_name: docker-socket-proxy
    restart: unless-stopped
    environment:
      # Permissions minimales n√©cessaires pour restart des conteneurs
      - CONTAINERS=1
      - POST=1
      # D√©sactiver tous les autres acc√®s
      - SERVICES=0
      - NETWORKS=0
      - IMAGES=0
      - VOLUMES=0
      - EXEC=0
      - BUILD=0
      - AUTH=0
      - COMMIT=0
      - PLUGINS=0
      - NODES=0
      - TASKS=0
      - SWARM=0
      - TIMEOUT_CONNECT=50000
      - TIMEOUT_CLIENT=50000
      - TIMEOUT_SERVER=50000
      # Timeout pour les connexions tunnel (events, attach, etc.)
      - TIMEOUT_TUNNEL=3600000
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 64M
        reservations:
          memory: 32M
    logging:
      driver: json-file
      options:
        max-size: 5m
        max-file: '2'
        compress: 'true'
    networks:
      - linkedin-network

  # ========================================
  # API (Pont entre Dashboard et Worker)
  # ========================================
  api:
    image: ghcr.io/gaspardd78/linkedin-birthday-auto-bot:latest
    container_name: bot-api
    ports:
    - "8000:8000"
    depends_on:
      redis-bot:
        condition: service_healthy
      docker-socket-proxy:
        condition: service_started
    command: uvicorn src.api.app:app --host 0.0.0.0 --port 8000
    # [SEC-1] D√©sactivation du mode privileged (Inutile avec la socket docker)
    privileged: false
    environment:
    - REDIS_HOST=redis-bot
    - REDIS_PORT=6379
    - PYTHONPATH=/app
    - LOG_LEVEL=INFO
    - DATABASE_URL=sqlite:///app/data/linkedin.db
      # Cl√© API pour s√©curiser les appels internes (OBLIGATOIRE)
      # G√©n√©rer avec: python -c "import secrets; print(secrets.token_hex(32))"
    - API_KEY=${API_KEY:?API_KEY doit √™tre d√©finie dans le fichier .env}
      # Activer la t√©l√©m√©trie OpenTelemetry
    - ENABLE_TELEMETRY=true
      # Endpoint OpenTelemetry (optionnel - d√©faut: http://localhost:4317)
    - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
      # Nom du service pour s√©parer les logs
    - SERVICE_NAME=api
      # Force l'utilisation du fichier config mont√© (pas celui baked-in dans l'image)
    - LINKEDIN_BOT_CONFIG_PATH=/app/config/config.yaml
      # [SEC-2] Utiliser docker-socket-proxy au lieu du socket direct
    - DOCKER_HOST=tcp://docker-socket-proxy:2375
    volumes:
    - ./logs:/app/logs
    - ./config:/app/config
    # Messages files are stored in /app/data/ and editable via API
    # auth_state.json is optional - can be uploaded to /app/data/auth_state.json via dashboard
    - ./data:/app/data
    # - ./src:/app/src  <-- Removed for production stability
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    restart: unless-stopped
    healthcheck:
      # Use Python to test HTTP health endpoint and verify status code 200
      test: ["CMD", "python", "-c", "import urllib.request; import sys; r = urllib.request.urlopen('http://localhost:8000/health'); sys.exit(0 if r.code == 200 else 1)"]
      interval: 30s
      timeout: 10s
      retries: 15
      start_period: 180s
    # [FIX-D] DNS fiables pour les appels API externes
    dns:
      - 1.1.1.1
      - 8.8.8.8
    networks:
    - linkedin-network

  # ========================================
  # BOT WORKER (RQ Worker avec Playwright)
  # ========================================
  bot-worker:
    image: ghcr.io/gaspardd78/linkedin-birthday-auto-bot:latest
    container_name: bot-worker
    depends_on:
      redis-bot:
        condition: service_healthy
    command: python -m src.queue.worker
    environment:
    - REDIS_HOST=redis-bot
    - REDIS_PORT=6379
    - PYTHONPATH=/app
    - LOG_LEVEL=INFO
      # Utilisation SQLite partag√© avec le dashboard
    - DATABASE_URL=sqlite:///app/data/linkedin.db
      # Activer la t√©l√©m√©trie OpenTelemetry
    - ENABLE_TELEMETRY=true
      # Endpoint OpenTelemetry (optionnel - d√©faut: http://localhost:4317)
    - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
      # Nom du service pour s√©parer les logs
    - SERVICE_NAME=worker
      # Force l'utilisation du fichier config mont√© (pas celui baked-in dans l'image)
    - LINKEDIN_BOT_CONFIG_PATH=/app/config/config.yaml
    volumes:
    - ./logs:/app/logs
    - ./config:/app/config
    # Messages files are stored in /app/data/ and editable via API
    # auth_state.json is optional - can be in environment variable or uploaded to /app/data/
    - ./data:/app/data
    # - ./src:/app/src  <-- Removed for production stability
    stop_signal: SIGINT
    # üöÄ OPTIMIS√â POUR RASPBERRY PI 4 (Multi-process with limits for stability)
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 1400M
        reservations:
          cpus: '0.5'
          memory: 800M
    logging:
      driver: json-file
      options:
        max-size: 5m
        max-file: '2'
        compress: 'true'
    restart: unless-stopped
    healthcheck:
      test: [CMD, python, -c, "import redis; r = redis.Redis(host='redis-bot', port=6379); r.ping()"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 60s
    # [FIX-D] DNS fiables - CRITIQUE pour connexion LinkedIn
    dns:
      - 1.1.1.1
      - 8.8.8.8
    networks:
    - linkedin-network

  # ========================================
  # DASHBOARD (Next.js avec SQLite)
  # ========================================
  dashboard:
    # Dashboard utilise l'image officielle depuis GHCR
    # (plus de build local pour √©conomiser ressources Pi4)
    image: ghcr.io/gaspardd78/linkedin-birthday-auto-dashboard:latest
    pull_policy: always
    restart: unless-stopped
    container_name: dashboard
    ports:
    - ${DASHBOARD_PORT:-3000}:3000
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 896M
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: json-file
      options:
        max-size: 5m
        max-file: '2'
        compress: 'true'
    env_file: .env
    environment:
    - NODE_ENV=production
    - NEXT_TELEMETRY_DISABLED=1
    - HOSTNAME=0.0.0.0
      # Optimisation M√©moire pour RPi4 (√©viter OOM Crash)
    - NODE_OPTIONS=--max-old-space-size=800

      # ‚úÖ SQLite Local
    - DATABASE_URL=sqlite:///app/data/linkedin.db

      # Configuration Redis Dashboard
    - REDIS_URL=redis://redis-dashboard:6379

      # Configuration Bot (pour Proxy API)
    - BOT_API_URL=http://api:8000
    - BOT_API_KEY=${API_KEY:?API_KEY doit √™tre d√©finie dans le fichier .env}

      # Configuration Authentification Dashboard (REQUIS)
    - JWT_SECRET=${JWT_SECRET}
    - DASHBOARD_USER=${DASHBOARD_USER}
    - DASHBOARD_PASSWORD=${DASHBOARD_PASSWORD}

      # Nom du service pour s√©parer les logs
    - SERVICE_NAME=dashboard
    volumes:
      # Logs partag√©s avec le bot
    - ./logs:/app/logs
      # Fichiers de configuration et messages (RW pour √©dition depuis Dashboard)
    - ./config:/app/config
      # Base de donn√©es SQLite partag√©e avec le bot
    - ./data:/app/data
      # Monitoring de temp√©rature du Raspberry Pi 4 (lecture seule)
    - /sys/class/thermal:/sys/class/thermal:ro
    depends_on:
      redis-dashboard:
        condition: service_healthy
      api:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/system/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    networks:
    - linkedin-network

  # ========================================
  # REVERSE PROXY (Nginx + SSL)
  # ========================================
  nginx:
    image: nginx:alpine
    container_name: nginx-proxy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./deployment/nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./deployment/nginx/linkedin-bot.conf:/etc/nginx/conf.d/default.conf
      - ./deployment/nginx/rate-limit-zones.conf:/etc/nginx/conf.d/rate-limit-zones.conf
      - ./deployment/nginx/options-ssl-nginx.conf:/etc/nginx/conf.d/options-ssl-nginx.conf
      - ./deployment/nginx/ssl-dhparams.pem:/etc/nginx/conf.d/ssl-dhparams.pem
      - ./deployment/nginx/429.html:/var/www/html/429.html
      - ./certbot/conf:/etc/letsencrypt
      - ./certbot/www:/var/www/certbot
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 64M
        reservations:
          cpus: '0.1'
          memory: 32M
    depends_on:
      - dashboard
      - api
    # [FIX-D] DNS fiables pour r√©solution ACME/Certbot
    dns:
      - 1.1.1.1
      - 8.8.8.8
    # [FIX-B] Healthcheck avec validation config Nginx
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - linkedin-network

  # ========================================
  # LOG VIEWER (Dozzle - remplace Prometheus/Grafana)
  # ========================================
  dozzle:
    image: amir20/dozzle:latest
    container_name: dozzle
    restart: unless-stopped
    ports:
      - "8080:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 64M
        reservations:
          cpus: '0.1'
          memory: 32M
    logging:
      driver: json-file
      options:
        max-size: 5m
        max-file: '2'
        compress: 'true'
    networks:
      - linkedin-network

# ========================================
# VOLUMES PERSISTANTS
# ========================================
volumes:
  redis-bot-data:
    name: linkedin-bot-redis-data
  redis-dashboard-data:
    name: linkedin-dashboard-redis-data

# ========================================
# R√âSEAU INTERNE
# ========================================
networks:
  linkedin-network:
    name: linkedin-network
    driver: bridge
    # [FIX-D] DNS fiables forc√©s - √©vite les timeouts DNS sur box FAI
    driver_opts:
      com.docker.network.bridge.enable_ip_masquerade: "true"
    ipam:
      driver: default
      config:
        - subnet: 172.28.0.0/16
    # DNS publics fiables (Cloudflare + Google) pour tous les conteneurs
    # R√©sout les probl√®mes de r√©solution DNS sur Freebox/box FAI
    # Note: Les DNS sont configur√©s au niveau du daemon Docker (/etc/docker/daemon.json)
