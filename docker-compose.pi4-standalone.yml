# Docker Compose pour Raspberry Pi 4 - Configuration Standalone
# Tout-en-un : Bot Worker + Dashboard + Redis
# Pas de dépendance externe (Synology MySQL/NFS retiré)
#
# Architecture simplifiée:
# - Pi4 : Bot Worker + Dashboard + Redis + SQLite
# - Freebox Pop : IP résidentielle légitime pour LinkedIn
#
# Utilisation:
#   docker compose -f docker-compose.pi4-standalone.yml up -d
#
# Documentation:
# - Setup: docs/RASPBERRY_PI_DOCKER_SETUP.md
# - Troubleshooting: docs/RASPBERRY_PI_TROUBLESHOOTING.md
# - Verification: ./scripts/verify_rpi_docker.sh

services:
  # ========================================
  # REDIS (Queue pour Bot Worker)
  # ========================================
  redis-bot:
    image: redis:7-alpine
    container_name: linkedin-bot-redis
    volumes:
      - redis-bot-data:/data
    # Optimisations Redis pour Pi 4
    command: >
      redis-server
      --appendonly yes
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --loglevel warning
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 300M
        reservations:
          cpus: '0.25'
          memory: 200M
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 5s
      retries: 3
    networks:
      - linkedin-network

  # ========================================
  # REDIS (Cache pour Dashboard)
  # ========================================
  redis-dashboard:
    image: redis:7-alpine
    container_name: linkedin-dashboard-redis
    command: >
      redis-server
      --maxmemory 128mb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --loglevel warning
    restart: unless-stopped
    volumes:
      - redis-dashboard-data:/data
    deploy:
      resources:
        limits:
          memory: 150M
          cpus: '0.5'
        reservations:
          memory: 100M
          cpus: '0.25'
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 5s
      retries: 3
    networks:
      - linkedin-network

  # ========================================
  # BOT WORKER (RQ Worker avec Playwright)
  # ========================================
  bot-worker:
    build:
      context: .
      dockerfile: Dockerfile.multiarch
    container_name: linkedin-bot-worker
    command: python -m src.queue.worker
    depends_on:
      redis-bot:
        condition: service_healthy
    environment:
      - REDIS_HOST=redis-bot
      - REDIS_PORT=6379
      - PYTHONPATH=/app
      - LOG_LEVEL=INFO
      # Utilisation SQLite partagé avec le dashboard
      - DATABASE_URL=sqlite:///app/data/linkedin.db
    volumes:
      - ./logs:/app/logs
      - ./config:/app/config:ro
      - ./auth_state.json:/app/auth_state.json
      - shared-data:/app/data
    # Optimisé pour Pi 4 avec 4GB RAM
    # Bot Worker: 1.2GB (Chromium + Python)
    # Dashboard: 1GB
    # Redis: 450MB (2x)
    # Système: 500MB
    # = ~3.15GB utilisés, laisse ~850MB libre
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 1.2G
        reservations:
          cpus: '1.0'
          memory: 800M
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import redis; r = redis.Redis(host='redis-bot', port=6379); r.ping()"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - linkedin-network

  # ========================================
  # DASHBOARD (Next.js avec SQLite)
  # ========================================
  dashboard:
    build:
      context: ./dashboard
      dockerfile: Dockerfile.prod.pi4
    restart: unless-stopped
    container_name: linkedin-dashboard
    ports:
      - "${DASHBOARD_PORT:-3000}:3000"
    deploy:
      resources:
        limits:
          memory: 1G      # Réduit pour Pi 4
          cpus: '1.5'     # Limité à 1.5 CPU cores
        reservations:
          memory: 600M
          cpus: '0.5'
    environment:
      - NODE_ENV=production
      - NEXT_TELEMETRY_DISABLED=1

      # ✅ SQLite Local (pas de MySQL Synology)
      - DATABASE_URL=sqlite:///app/data/linkedin.db

      # Configuration Redis Dashboard
      - REDIS_URL=redis://redis-dashboard:6379

      # Configuration Puppeteer (si utilisé dans le dashboard)
      - HEADLESS=true
      - PUPPETEER_ARGS=--no-sandbox,--disable-setuid-sandbox,--disable-dev-shm-usage,--disable-gpu

      # Configuration Bot (optionnel)
      - BOT_REDIS_URL=redis://redis-bot:6379
    volumes:
      # Logs partagés avec le bot
      - ./logs:/app/logs
      # Base de données SQLite partagée avec le bot
      - shared-data:/app/data
    depends_on:
      redis-dashboard:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - linkedin-network

# ========================================
# VOLUMES PERSISTANTS
# ========================================
volumes:
  redis-bot-data:
    name: linkedin-bot-redis-data
  redis-dashboard-data:
    name: linkedin-dashboard-redis-data
  shared-data:
    name: linkedin-shared-data
    # Volume partagé entre le bot et le dashboard pour SQLite

# ========================================
# RÉSEAU INTERNE
# ========================================
networks:
  linkedin-network:
    name: linkedin-network
    driver: bridge
