# Guide du Scraping de Profils LinkedIn

## üìã Vue d'ensemble

Le `VisitorBot` a √©t√© am√©lior√© pour scraper automatiquement les donn√©es d√©taill√©es de chaque profil visit√© et les sauvegarder dans une base de donn√©es SQLite avec export CSV.

## üéØ Donn√©es collect√©es

Pour chaque profil visit√©, le bot collecte :

- **Nom complet** (`full_name`)
- **Pr√©nom** (`first_name`)
- **Nom de famille** (`last_name`)
- **Niveau de relation** (`relationship_level`) : 1er, 2e, 3e degr√©
- **Entreprise actuelle** (`current_company`)
- **Formation** (`education`) : Premier dipl√¥me/√©tablissement
- **Ann√©es d'exp√©rience** (`years_experience`) : Calcul√©es automatiquement
- **URL du profil** (`profile_url`)
- **Date de scraping** (`scraped_at`)

## üöÄ Utilisation

### 1. Lancer le VisitorBot avec scraping

Le scraping est automatiquement activ√© lors de l'ex√©cution du VisitorBot :

```bash
# Mode production (visite r√©elle + scraping)
python main.py --mode visitor

# Mode dry-run (simulation sans visite)
python main.py --mode visitor --dry-run
```

### 2. Exporter les donn√©es en CSV

Utilisez le script d'export pour g√©n√©rer un fichier CSV :

```bash
# Export avec nom par d√©faut (scraped_profiles_YYYY-MM-DD.csv)
python export_scraped_data.py

# Export vers un fichier sp√©cifique
python export_scraped_data.py my_profiles.csv

# Export vers un r√©pertoire sp√©cifique
python export_scraped_data.py exports/linkedin_profiles.csv

# Voir uniquement les statistiques (sans exporter)
python export_scraped_data.py --stats
```

### 3. Consulter les statistiques

```bash
# Afficher les statistiques sans exporter
python export_scraped_data.py --stats
```

Cela affichera :
- Nombre total de profils scrap√©s
- Top 5 des entreprises
- R√©partition par niveau de relation

## üìä Format du CSV export√©

Le fichier CSV contient les colonnes suivantes (s√©parateur `,`) :

```csv
profile_url,first_name,last_name,full_name,relationship_level,current_company,education,years_experience,scraped_at
https://linkedin.com/in/john-doe,John,Doe,John Doe,1er,Acme Corp,MIT,12,2025-11-28T14:30:00
```

## üîß Architecture technique

### Base de donn√©es

Une nouvelle table `scraped_profiles` a √©t√© ajout√©e √† la base SQLite :

```sql
CREATE TABLE scraped_profiles (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    profile_url TEXT UNIQUE NOT NULL,
    first_name TEXT,
    last_name TEXT,
    full_name TEXT,
    relationship_level TEXT,
    current_company TEXT,
    education TEXT,
    years_experience INTEGER,
    scraped_at TEXT NOT NULL
)
```

### M√©thodes ajout√©es

#### Dans `src/core/database.py`

- `save_scraped_profile(...)` : Enregistre ou met √† jour (UPSERT) un profil
- `get_scraped_profile(profile_url)` : R√©cup√®re un profil par URL
- `get_all_scraped_profiles(limit)` : R√©cup√®re tous les profils
- `export_scraped_data_to_csv(output_path)` : Export CSV avec gestion UTF-8

#### Dans `src/bots/visitor_bot.py`

- `_scrape_profile_data()` : Scrape les donn√©es d'un profil LinkedIn
- `_save_scraped_profile_data(scraped_data)` : Sauvegarde en base

## üõ°Ô∏è Gestion des erreurs

Le scraping est **non-bloquant** :
- Si un √©l√©ment n'est pas trouv√©, la valeur par d√©faut est `"Unknown"` ou `None`
- Les erreurs de scraping sont logu√©es mais ne font pas planter le bot
- La visite de profil continue m√™me si le scraping √©choue partiellement

## üìù Logs

Le bot g√©n√®re des logs d√©taill√©s :

```
[INFO] Donn√©es r√©cup√©r√©es pour John Doe (Acme Corp)
[INFO] ‚úÖ Scraped data saved for John Doe
[DEBUG] Could not extract education: Timeout
```

## üé® S√©lecteurs LinkedIn

Le bot utilise plusieurs s√©lecteurs de secours pour g√©rer les variations du DOM LinkedIn :

- **Nom** : `h1.text-heading-xlarge`, `h1.inline`, `div.ph5 h1`
- **Relation** : `span.dist-value`, `div.pv-top-card--list-bullet li`
- **Entreprise** : `div.text-body-medium`, section Exp√©rience
- **Formation** : `section:has-text("Formation")`, `section:has-text("Education")`
- **Exp√©rience** : Parsing des dates dans la section Exp√©rience

## üîÑ UPSERT automatique

Si un profil est visit√© plusieurs fois, ses donn√©es sont **mises √† jour** automatiquement gr√¢ce √† la contrainte `UNIQUE` sur `profile_url`.

## üìà Performance

- **Scraping non-bloquant** : N'ajoute que quelques secondes au temps de visite
- **Base SQLite optimis√©e** : Mode WAL, indexes sur `profile_url` et `scraped_at`
- **Export CSV rapide** : Gestion efficace de l'UTF-8 et des caract√®res sp√©ciaux

## üêõ Troubleshooting

### Le scraping ne fonctionne pas

1. V√©rifier que la base de donn√©es est activ√©e dans `config.yaml` :
   ```yaml
   database:
     enabled: true
     db_path: "linkedin_automation.db"
   ```

2. V√©rifier les logs pour voir si des s√©lecteurs ont √©chou√©

3. LinkedIn a peut-√™tre chang√© son DOM ‚Üí Adapter les s√©lecteurs dans `_scrape_profile_data()`

### Le CSV est vide

1. V√©rifier que des profils ont √©t√© visit√©s : `python export_scraped_data.py --stats`
2. V√©rifier que la base de donn√©es existe : `ls -lh linkedin_automation.db`

### Caract√®res mal encod√©s dans le CSV

Le CSV utilise UTF-8 par d√©faut. Pour ouvrir correctement dans Excel :
1. Ouvrir Excel
2. Donn√©es ‚Üí Depuis un fichier texte/CSV
3. Choisir l'encodage UTF-8

## üîê Conformit√© et √©thique

- ‚ö†Ô∏è Respectez les conditions d'utilisation de LinkedIn
- üîí Ne partagez pas les donn√©es scrap√©es publiquement
- ü§ñ Utilisez des d√©lais r√©alistes pour simuler un comportement humain
- üìú Ce projet est √† des fins √©ducatives et personnelles

## üìö Exemples d'utilisation

### Exemple 1 : Export quotidien automatis√©

```bash
#!/bin/bash
# Cron job pour export quotidien
cd /path/to/linkedin-birthday-auto
python export_scraped_data.py exports/profiles_$(date +%Y%m%d).csv
```

### Exemple 2 : Analyse avec pandas

```python
import pandas as pd

# Charger le CSV
df = pd.read_csv('scraped_profiles.csv')

# Top 10 entreprises
print(df['current_company'].value_counts().head(10))

# Moyenne d'ann√©es d'exp√©rience
print(f"Moyenne: {df['years_experience'].mean():.1f} ans")

# Filtrer par niveau de relation
first_degree = df[df['relationship_level'].str.contains('1er|1st')]
print(f"Contacts de 1er degr√©: {len(first_degree)}")
```

## üéØ Prochaines am√©liorations possibles

- [ ] Scraping des comp√©tences (skills)
- [ ] Extraction des recommandations
- [ ] Historique complet des exp√©riences
- [ ] Export JSON en plus du CSV
- [ ] Dashboard de visualisation des donn√©es scrap√©es
- [ ] D√©tection automatique des changements de poste

---

**Version** : 2.1.0
**Derni√®re mise √† jour** : 2025-11-28
