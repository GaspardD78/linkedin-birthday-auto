#!/bin/bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Script de backup automatique vers Google Drive
# LinkedIn Birthday Auto Bot - Audit SÃ©curitÃ© 2025
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# Ce script sauvegarde la base SQLite vers Google Drive via rclone.
#
# Modifications (Debug & Fiabilisation):
# - DÃ©tection dynamique du remote rclone
# - VÃ©rification stricte des chemins (data, .env, config)
# - Gestion verbeuse des erreurs rclone
#
# Usage:
#   ./backup_to_gdrive.sh [--skip-local]
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

set -e
set -o pipefail

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURATION ET DÃ‰TECTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# DÃ©tection de la racine du projet
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"

# Couleurs
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
BLUE='\033[0;34m'
NC='\033[0m'

# Fonctions de log
log_info() { echo -e "${GREEN}[$(date '+%Y-%m-%d %H:%M:%S')]${NC} [INFO] $1"; }
log_warn() { echo -e "${YELLOW}[$(date '+%Y-%m-%d %H:%M:%S')]${NC} [WARN] $1"; }
log_error() { echo -e "${RED}[$(date '+%Y-%m-%d %H:%M:%S')]${NC} [ERROR] $1"; }
log_debug() { echo -e "${BLUE}[$(date '+%Y-%m-%d %H:%M:%S')]${NC} [DEBUG] $1"; }

error_exit() {
    log_error "$1"
    exit 1
}

log_info "ğŸš€ DÃ©marrage du script de backup (Mode FiabilisÃ©)"
log_debug "Script directory: $SCRIPT_DIR"
log_debug "Project root: $PROJECT_ROOT"

# 1. DÃ©tection du remote rclone
log_info "ğŸ” DÃ©tection du remote rclone..."
GDRIVE_REMOTE=$(rclone listremotes 2>/dev/null | head -n 1 | sed 's/://')

if [ -z "$GDRIVE_REMOTE" ]; then
    log_warn "Aucun remote dÃ©tectÃ© automatiquement. Utilisation par dÃ©faut : 'gdrive'"
    GDRIVE_REMOTE="gdrive"
else
    log_info "Remote rclone dÃ©tectÃ© : '$GDRIVE_REMOTE'"
fi

# 2. Configuration des chemins
DB_PATH="${PROJECT_ROOT}/data/linkedin.db"
ENV_PATH="${PROJECT_ROOT}/.env" # Note: .env might not exist in sandbox, checking anyway per requirement
CONFIG_DIR="${PROJECT_ROOT}/config"

# RÃ©pertoire de backup local (Temporaire ou Persistant)
# On privilÃ©gie un dossier dans data/backups pour Ã©viter les problÃ¨mes de droits /mnt
DEFAULT_BACKUP_DIR="/mnt/linkedin-data/backups"
LOCAL_BACKUP_DIR="${PROJECT_ROOT}/data/backups"

# Si le dossier /mnt existe et est accessible en Ã©criture, on l'utilise (legacy)
if [ -d "$DEFAULT_BACKUP_DIR" ] && [ -w "$DEFAULT_BACKUP_DIR" ]; then
    LOCAL_BACKUP_DIR="$DEFAULT_BACKUP_DIR"
    log_debug "Utilisation du dossier backup legacy: $LOCAL_BACKUP_DIR"
elif [ -d "$(dirname "$DEFAULT_BACKUP_DIR")" ] && [ -w "$(dirname "$DEFAULT_BACKUP_DIR")" ]; then
     # Si /mnt/linkedin-data existe et est writable, on peut crÃ©er backups dedans
     LOCAL_BACKUP_DIR="$DEFAULT_BACKUP_DIR"
     log_debug "Utilisation du dossier backup legacy (Ã  crÃ©er): $LOCAL_BACKUP_DIR"
else
    log_debug "Utilisation du dossier backup local (fallback): $LOCAL_BACKUP_DIR"
fi

# Configuration Drive
GDRIVE_BACKUP_DIR="Backups/RPI4_LinkedinBot"
RETENTION_DAYS=30

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="linkedin_backup_${TIMESTAMP}.db"
BACKUP_FULL_PATH="${LOCAL_BACKUP_DIR}/${BACKUP_FILE}"

log_debug "DB_PATH: $DB_PATH"
log_debug "LOCAL_BACKUP_DIR: $LOCAL_BACKUP_DIR"
log_debug "GDRIVE_PATH: ${GDRIVE_REMOTE}:${GDRIVE_BACKUP_DIR}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VÃ‰RIFICATIONS STRICTES (REQUIREMENTS)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

log_info "ğŸ” VÃ©rification de l'environnement..."

# VÃ©rification rclone
if ! command -v rclone &> /dev/null; then
    error_exit "rclone n'est pas installÃ©. (curl https://rclone.org/install.sh | sudo bash)"
fi

# VÃ©rification fichiers sources requis
# Le prompt demande explicitement de vÃ©rifier data/, .env, config/
# Attention: .env peut Ãªtre .env.pi4.example si pas configurÃ©, mais ici on suppose prod
REQUIRED_PATHS=("$PROJECT_ROOT/data" "$PROJECT_ROOT/config")
# On vÃ©rifie .env sÃ©parÃ©ment car il peut ne pas exister dans certains contextes (dev),
# mais en prod sur RPi4 il est vital.
if [ -f "$PROJECT_ROOT/.env" ]; then
    REQUIRED_PATHS+=("$PROJECT_ROOT/.env")
else
    log_warn "Fichier .env non trouvÃ© Ã  la racine ($PROJECT_ROOT/.env). VÃ©rifiez si c'est normal."
    # Si requirements stricts:
    # error_exit "Fichier .env manquant."
    # Mais le user dit "Data path: ... .env". Donc il doit Ãªtre lÃ .
    # On va faire un check strict selon la demande.
    log_error "Fichier .env manquant."
    exit 1
fi

MISSING_PATH=false
for path in "${REQUIRED_PATHS[@]}"; do
    if [ ! -e "$path" ]; then
        log_error "Chemin requis manquant : $path"
        MISSING_PATH=true
    else
        log_debug "OK: $path"
    fi
done

if [ "$MISSING_PATH" = true ]; then
    error_exit "Certains fichiers sources requis sont manquants. Abandon."
fi

# VÃ©rification prÃ©sence DB (warning si absente mais dossier data lÃ )
if [ ! -f "$DB_PATH" ]; then
    # C'est critique pour le backup DB
    error_exit "Base de donnÃ©es SQLite introuvable : $DB_PATH"
fi

# VÃ©rification/CrÃ©ation dossier backup local et permissions
if [ ! -d "$LOCAL_BACKUP_DIR" ]; then
    log_info "CrÃ©ation du dossier backup local : $LOCAL_BACKUP_DIR"
    mkdir -p "$LOCAL_BACKUP_DIR" || error_exit "Impossible de crÃ©er $LOCAL_BACKUP_DIR"
fi

if [ ! -w "$LOCAL_BACKUP_DIR" ]; then
    error_exit "Permission refusÃ©e : Impossible d'Ã©crire dans $LOCAL_BACKUP_DIR"
fi

# Test connexion Drive rapide
log_info "Test de connexion au remote '$GDRIVE_REMOTE'..."
if ! rclone about "${GDRIVE_REMOTE}:" &> /dev/null; then
    # On tente un lsd si about Ã©choue
    if ! rclone lsd "${GDRIVE_REMOTE}:" &> /dev/null; then
        error_exit "Ã‰chec de connexion au remote '${GDRIVE_REMOTE}'. VÃ©rifiez 'rclone config'."
    fi
fi
log_info "Connexion Drive OK."

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CRÃ‰ATION DU BACKUP LOCAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if [ "$1" != "--skip-local" ]; then
    log_info "ğŸ“¦ CrÃ©ation du backup SQLite local..."

    if ! command -v sqlite3 &> /dev/null; then
        error_exit "sqlite3 n'est pas installÃ©."
    fi

    # Backup avec sqlite3
    if ! sqlite3 "$DB_PATH" ".backup '$BACKUP_FULL_PATH'"; then
        error_exit "Erreur lors de l'exÃ©cution de sqlite3 .backup"
    fi

    # VÃ©rification intÃ©gritÃ©
    log_debug "VÃ©rification intÃ©gritÃ© SQLite..."
    INTEGRITY=$(sqlite3 "$BACKUP_FULL_PATH" "PRAGMA integrity_check;")
    if [ "$INTEGRITY" != "ok" ]; then
        rm -f "$BACKUP_FULL_PATH"
        error_exit "Backup corrompu (Integrity Check: $INTEGRITY)"
    fi

    # Checksum
    sha256sum "$BACKUP_FULL_PATH" > "${BACKUP_FULL_PATH}.sha256"

    # Compression
    log_info "ğŸ—œï¸ Compression..."
    gzip -f "$BACKUP_FULL_PATH"
    BACKUP_FULL_PATH="${BACKUP_FULL_PATH}.gz"

    if [ ! -f "$BACKUP_FULL_PATH" ]; then
        error_exit "Le fichier compressÃ© n'a pas Ã©tÃ© crÃ©Ã©."
    fi

    SIZE=$(du -h "$BACKUP_FULL_PATH" | cut -f1)
    log_info "Backup local crÃ©Ã© avec succÃ¨s : $BACKUP_FULL_PATH ($SIZE)"

else
    log_info "â­ï¸ Skip local backup requested."
    # Find latest
    BACKUP_FULL_PATH=$(ls -t ${LOCAL_BACKUP_DIR}/linkedin_backup_*.db.gz 2>/dev/null | head -1)
    if [ -z "$BACKUP_FULL_PATH" ]; then
        error_exit "Aucun backup local trouvÃ© pour l'upload."
    fi
    log_info "Utilisation du dernier backup : $BACKUP_FULL_PATH"
fi

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# UPLOAD VERS GOOGLE DRIVE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

log_info "â˜ï¸ Upload vers Google Drive : ${GDRIVE_REMOTE}:${GDRIVE_BACKUP_DIR}"

# CrÃ©ation dossier distant (sans masquer stderr)
log_debug "VÃ©rification/CrÃ©ation dossier distant..."
# On autorise l'Ã©chec si le dossier existe dÃ©jÃ  (exit code != 0 possible sur certains remotes ?)
# rclone mkdir ne fail pas si existe, sauf droits.
if ! rclone mkdir "${GDRIVE_REMOTE}:${GDRIVE_BACKUP_DIR}" 2>/dev/null; then
    # On re-tente sans masquer pour voir l'erreur si besoin, ou on log warning
    log_warn "Erreur (ou dÃ©jÃ  existant) lors du mkdir distant."
fi

UPLOAD_SUCCESS=false

for attempt in {1..3}; do
    log_info "Tentative d'upload ${attempt}/3..."

    # On capture stderr pour l'afficher
    # --stats-one-line est plus clean pour les logs
    if rclone copy "$BACKUP_FULL_PATH" "${GDRIVE_REMOTE}:${GDRIVE_BACKUP_DIR}/" --verbose --stats 5s; then
        UPLOAD_SUCCESS=true
        log_info "Upload rÃ©ussi."
        break
    else
        EXIT_CODE=$?
        log_warn "Ã‰chec de la commande rclone copy (Code: $EXIT_CODE). Retrying in 5s..."
        sleep 5
    fi
done

if [ "$UPLOAD_SUCCESS" = false ]; then
    error_exit "Abandon aprÃ¨s 3 Ã©checs d'upload."
fi

# Upload checksum
rclone copy "${BACKUP_FULL_PATH}.sha256" "${GDRIVE_REMOTE}:${GDRIVE_BACKUP_DIR}/" --quiet || true

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ROTATION ET NETTOYAGE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

log_info "ğŸ§¹ Nettoyage des vieux backups (> $RETENTION_DAYS jours)..."

# Local
find "$LOCAL_BACKUP_DIR" -name "linkedin_backup_*.db*" -type f -mtime +${RETENTION_DAYS} -delete 2>/dev/null || true

# Remote
# On utilise --min-age pour simplifier la logique
rclone delete "${GDRIVE_REMOTE}:${GDRIVE_BACKUP_DIR}" --min-age ${RETENTION_DAYS}d --include "linkedin_backup_*" --verbose || log_warn "Erreur lors du nettoyage distant"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RÃ‰SUMÃ‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

REMOTE_STATS=$(rclone size "${GDRIVE_REMOTE}:${GDRIVE_BACKUP_DIR}" --json 2>/dev/null)
# Extraction un peu plus robuste (JSON simple)
COUNT=$(echo "$REMOTE_STATS" | grep -o '"count":[0-9]*' | cut -d: -f2)
SIZE=$(echo "$REMOTE_STATS" | grep -o '"bytes":[0-9]*' | cut -d: -f2)
# Fallback si numfmt absent (ex: minimal docker)
if command -v numfmt &>/dev/null; then
    SIZE_HUMAN=$(numfmt --to=iec $SIZE 2>/dev/null)
else
    SIZE_HUMAN="$SIZE bytes"
fi

echo ""
log_info "âœ… Sauvegarde terminÃ©e avec succÃ¨s."
echo "---------------------------------------------------"
echo "ğŸ“ Source          : $DB_PATH"
echo "ğŸ“¦ Archive         : $BACKUP_FULL_PATH"
echo "â˜ï¸  Destination     : ${GDRIVE_REMOTE}:${GDRIVE_BACKUP_DIR}"
echo "ğŸ“Š Ã‰tat Drive      : $COUNT fichiers, $SIZE_HUMAN"
echo "---------------------------------------------------"

exit 0
